# è‡ªåŠ¨åŒ–å®éªŒè¿è¡Œå™¨ä½¿ç”¨æŒ‡å—

## å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨OllamaæœåŠ¡ï¼ˆé¦–æ¬¡è¿è¡Œæˆ–éœ€è¦ç‰¹å®šé…ç½®ï¼‰

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡å¯ç”¨Flash Attentionå’ŒKV Cache
export OLLAMA_FLASH_ATTENTION=1
export OLLAMA_KV_CACHE_TYPE=q8_0

# å¯åŠ¨OllamaæœåŠ¡
ollama serve
```

**æ³¨æ„**: åœ¨å¦ä¸€ä¸ªç»ˆç«¯çª—å£è¿è¡Œå®éªŒï¼Œä¿æŒOllamaæœåŠ¡è¿è¡Œã€‚

### 2. è¿è¡Œå®éªŒ

```bash
cd /home/user/ai_agent/chatbot/tests/prompts4test/test
python3 run_experiments.py --rounds 5 10 20
```

## æ ¸å¿ƒæ¦‚å¿µ

### å®éªŒè®¾è®¡
æœ¬å·¥å…·ç”¨äºè¯„ä¼°ï¼š**åœ¨å›ºå®šçš„æµ‹è¯•æ•°æ®ä¸Šï¼Œä¸åŒçš„åˆ†å—å¤§å°Nå¯¹å¤„ç†æ—¶é—´å’Œå‡†ç¡®æ€§çš„å½±å“**

```
å›ºå®šæµ‹è¯•æ•°æ® (chats/mock_user/)
        â†“
    æŒ‰ N è½®åˆ†å—å¤„ç†
        â†“
å­˜å‚¨åˆ° MemoBase (éšæœº User ID)
        â†“
    è¯„ä¼°å‡†ç¡®ç‡å’Œæ—¶é—´
```

### å…³é”®å‚æ•°

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **æµ‹è¯•æ•°æ®æº** | å›ºå®šè·¯å¾„ï¼Œæ‰€æœ‰å®éªŒå…±ç”¨ | `chats/mock_user/` |
| **MemoBase User ID** | æ¯æ¬¡å®éªŒéšæœºç”Ÿæˆ4ä½å­—ç¬¦ä¸² | `x7k2`, `a3d9`, `m5p1` |
| **N (rounds)** | æ¯ä¸ªchunkåŒ…å«çš„å¯¹è¯è½®æ•°ï¼ˆå˜é‡ï¼‰ | 5, 10, 20 |

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**
- âœ… å›ºå®šæ•°æ®æº â†’ ä¿è¯å®éªŒå¯æ¯”æ€§
- âœ… éšæœºUser ID â†’ ç¡®ä¿å®éªŒç‹¬ç«‹æ€§ï¼Œä¸äº’ç›¸å½±å“
- âœ… åªå˜åŒ–N â†’ å‡†ç¡®è¯„ä¼°åˆ†å—å¤§å°çš„å½±å“

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬å‘½ä»¤

```bash
# æµ‹è¯•å¤šä¸ªNå€¼
python3 run_experiments.py --rounds 5 10 20

# æµ‹è¯•æ›´å¹¿æ³›çš„Nå€¼èŒƒå›´
python3 run_experiments.py --rounds 3 5 7 10 15 20 30

# è‡ªå®šä¹‰å®éªŒå‰ç¼€
python3 run_experiments.py --rounds 5 10 --user-prefix mytest

# è·³è¿‡è¯„ä¼°ï¼ˆä»…æµ‹è¯•æ€§èƒ½ï¼‰
python3 run_experiments.py --rounds 5 10 20 --skip-eval
```

### å•ç‹¬è¿è¡Œextract.py

```bash
# ä½¿ç”¨é»˜è®¤éšæœºUser ID
python3 extract.py --rounds-per-chunk 5

# æŒ‡å®šUser IDï¼ˆç”¨äºè°ƒè¯•ï¼‰
python3 extract.py --rounds-per-chunk 5 --user-id test123
```

## è¾“å‡ºè¯´æ˜

### è¿è¡Œæ—¶è¾“å‡º

```
================================================================================
AUTOMATED EXPERIMENT RUNNER
================================================================================
Configurations: Flash Attention=1, KV Cache=q8_0
Chat data source: chats/mock_user/
Rounds to test: [5, 10, 20]
================================================================================
================================================================================
Warming up model...
================================================================================
âœ“ Model warmed up and ready

================================================================================
EXPERIMENT 1/3: N=5 rounds per chunk
Experiment ID: exp_n5_x7k2
MemoBase User ID: x7k2
================================================================================

  [1/3] Running extraction (N=5)...
      Processing all chat files in chats/mock_user/

MemoBase User ID: x7k2
Reading chat data from: chats/mock_user/
Rounds per chunk: 5

[Session 1/5] File: chats/mock_user/1.json
  Chunks in this session: 2
  Chunk 1: 5 user turns, 5 assistant replies [Overall: 1/33]
  Chunk 2: 3 user turns, 3 assistant replies [Overall: 2/33]
  Session processing time: 2.45s

[Session 2/5] File: chats/mock_user/2.json
  Chunks in this session: 1
  Chunk 1: 5 user turns, 5 assistant replies [Overall: 3/33]
  Session processing time: 1.23s

[... Sessions 3-5 ...]

âœ“ All 5 sessions processed (33 chunks total)
Cost time(s) 12.34

  âœ“ Extraction completed in 12.34s
  [2/3] Running evaluation...
  âœ“ Evaluation completed:
    - Precision: 0.892
    - Recall: 0.856
    - F1 Score: 0.874
    - Redundancy: 0.110
    - TP=145, FP=18, FN=24
  [3/3] Recording Ollama metrics...
  âœ“ Ollama metrics recorded:
    - TTFT: 0.123s
    - Prompt eval: 1.234s
    - Eval duration: 0.567s
    - Total duration: 2.456s

âœ“ Experiment 1/3 completed
  - Experiment ID: exp_n5_x7k2
  - MemoBase User ID: x7k2
```

### æœ€ç»ˆæ±‡æ€»

```
================================================================================
ALL EXPERIMENTS COMPLETED
================================================================================

ğŸ“Š Results Summary (Data source: chats/mock_user/):
   User ID |     N |   Duration |     TTFT | Precision |    Recall |        F1
------------------------------------------------------------------------------------------
      x7k2 |     5 |     12.34s |   0.123s |     0.892 |     0.856 |     0.874
      a3d9 |    10 |     15.67s |   0.145s |     0.910 |     0.875 |     0.892
      m5p1 |    20 |     22.89s |   0.178s |     0.925 |     0.890 |     0.907

ğŸ“ Detailed results saved to: results/experiment_summary_20250121_143156.json
```

## è®°å½•çš„æŒ‡æ ‡

### æ—¶é—´æŒ‡æ ‡
- **duration**: æå–æ€»æ—¶é—´ï¼ˆç§’ï¼‰
- **ttft**: Time To First Token - é¦–ä¸ªtokenç”Ÿæˆæ—¶é—´
- **prompt_eval_duration**: æç¤ºè¯è¯„ä¼°æ—¶é—´
- **eval_duration**: ç”Ÿæˆè¯„ä¼°æ—¶é—´
- **total_duration**: Ollamaæ€»å¤„ç†æ—¶é—´

### å‡†ç¡®æ€§æŒ‡æ ‡
- **precision**: ç²¾ç¡®ç‡ - æå–ä¿¡æ¯çš„å‡†ç¡®æ€§
- **recall**: å¬å›ç‡ - æå–ä¿¡æ¯çš„å®Œæ•´æ€§
- **f1**: F1åˆ†æ•° - ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
- **redundancy_rate**: å†—ä½™ç‡ - æ— å…³ä¿¡æ¯æ¯”ä¾‹
- **tp**: True Positives - æ­£ç¡®æå–çš„ä¿¡æ¯æ•°é‡
- **fp**: False Positives - é”™è¯¯æå–çš„ä¿¡æ¯æ•°é‡
- **fn**: False Negatives - é—æ¼çš„ä¿¡æ¯æ•°é‡

## ç»“æœæ–‡ä»¶

### JSONæ ¼å¼

ä½ç½®: `results/experiment_summary_<timestamp>.json`

```json
{
  "bench_n5_x7k2": {
    "experiment_id": "bench_n5_x7k2",
    "rounds": 5,
    "memobase_user_id": "x7k2",
    "chat_data_source": "chats/mock_user/",
    "duration": 12.34,
    "ttft": 0.123,
    "prompt_eval_duration": 1.234,
    "eval_duration": 0.567,
    "total_duration": 2.456,
    "precision": 0.892,
    "recall": 0.856,
    "f1": 0.874,
    "redundancy_rate": 0.110,
    "tp": 145,
    "fp": 18,
    "fn": 24
  }
}
```

## ç›®å½•ç»“æ„

```
test/
â”œâ”€â”€ chats/
â”‚   â”œâ”€â”€ mock_user/          # å›ºå®šçš„æµ‹è¯•æ•°æ®æºï¼ˆæ‰€æœ‰å®éªŒå…±ç”¨ï¼‰
â”‚   â”‚   â”œâ”€â”€ 1.json         # å¯¹è¯æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ 2.json
â”‚   â”‚   â”œâ”€â”€ 3.json
â”‚   â”‚   â”œâ”€â”€ 4.json
â”‚   â”‚   â””â”€â”€ 5.json
â”‚   â”œâ”€â”€ ground_truth/       # æ ‡å‡†ç­”æ¡ˆ
â”‚   â”‚   â”œâ”€â”€ 1.txt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ output/            # è¯„ä¼°è¾“å‡º
â”œâ”€â”€ logs/                  # Ollamaæ—¥å¿—
â”œâ”€â”€ results/               # å®éªŒç»“æœJSON
â”œâ”€â”€ run_experiments.py     # ä¸»å®éªŒè¿è¡Œå™¨
â”œâ”€â”€ extract.py            # ä¿¡æ¯æå–è„šæœ¬
â””â”€â”€ evaluate.py           # è¯„ä¼°è„šæœ¬
```

## å®éªŒæµç¨‹è¯¦è§£

### å•ä¸ªå®éªŒçš„å®Œæ•´æµç¨‹

ä»¥ N=5 ä¸ºä¾‹ï¼š

1. **ç”ŸæˆéšæœºUser ID**: `x7k2`
2. **é…ç½®Ollama**: å¯ç”¨Flash Attentionå’ŒKV Cache
3. **è¯»å–æ•°æ®**: ä» `chats/mock_user/` è¯»å–æ‰€æœ‰5ä¸ªJSONæ–‡ä»¶
4. **åˆ†å—å¤„ç†**: æ¯5è½®å¯¹è¯åˆ†æˆä¸€ä¸ªchunk
5. **æ’å…¥MemoBase**: ä½¿ç”¨User ID `x7k2` å­˜å‚¨
6. **è¯„ä¼°**: è®¡ç®—precisionã€recallã€F1ç­‰æŒ‡æ ‡
7. **è®°å½•æ€§èƒ½**: TTFTã€å¤„ç†æ—¶é—´ç­‰

### å¤šä¸ªå®éªŒçš„å¯¹æ¯”

| å®éªŒ | User ID | æ•°æ®æº | Nå€¼ | åˆ†å—æ–¹å¼ | ç»“æœ |
|------|---------|--------|-----|----------|------|
| 1 | x7k2 | mock_user | 5 | æ¯5è½®ä¸€å— | P=0.892, F1=0.874 |
| 2 | a3d9 | mock_user | 10 | æ¯10è½®ä¸€å— | P=0.910, F1=0.892 |
| 3 | m5p1 | mock_user | 20 | æ¯20è½®ä¸€å— | P=0.925, F1=0.907 |

**å…³é”®ç‚¹ï¼š**
- âœ… ç›¸åŒæ•°æ®æº â†’ ç»“æœå¯æ¯”
- âœ… ä¸åŒUser ID â†’ å®éªŒç‹¬ç«‹
- âœ… ä¸åŒNå€¼ â†’ å‡†ç¡®è¯„ä¼°å½±å“

## ç»“æœåˆ†æ

### åˆ†æNå€¼çš„å½±å“

```python
import json
import matplotlib.pyplot as plt

# è¯»å–ç»“æœ
with open('results/experiment_summary_xxx.json') as f:
    data = json.load(f)

# æå–æ•°æ®
rounds = [v['rounds'] for v in data.values()]
f1_scores = [v['f1'] for v in data.values()]
durations = [v['duration'] for v in data.values()]

# ç»˜å›¾
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

ax1.plot(rounds, f1_scores, marker='o')
ax1.set_xlabel('Rounds per Chunk (N)')
ax1.set_ylabel('F1 Score')
ax1.set_title('Accuracy vs N')

ax2.plot(rounds, durations, marker='o', color='orange')
ax2.set_xlabel('Rounds per Chunk (N)')
ax2.set_ylabel('Duration (s)')
ax2.set_title('Processing Time vs N')

plt.tight_layout()
plt.savefig('experiment_analysis.png')
```

### æ‰¾åˆ°æœ€ä½³Nå€¼

```python
# è®¡ç®—æ•ˆç‡åˆ†æ•°ï¼ˆè€ƒè™‘æ—¶é—´å’Œå‡†ç¡®æ€§ï¼‰
for exp_id, metrics in data.items():
    efficiency = metrics['f1'] / metrics['duration']
    print(f"N={metrics['rounds']:2d}: "
          f"F1={metrics['f1']:.3f}, "
          f"Time={metrics['duration']:6.2f}s, "
          f"Efficiency={efficiency:.4f}")

# è¾“å‡ºç¤ºä¾‹ï¼š
# N= 5: F1=0.874, Time= 12.34s, Efficiency=0.0708
# N=10: F1=0.892, Time= 15.67s, Efficiency=0.0569
# N=20: F1=0.907, Time= 22.89s, Efficiency=0.0396
```

## å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆæ¯æ¬¡å®éªŒè¦ç”¨ä¸åŒçš„MemoBase User IDï¼Ÿ
**A:** ç¡®ä¿æ¯ä¸ªå®éªŒéƒ½æ˜¯ç‹¬ç«‹çš„ã€å¹²å‡€çš„ã€‚å¦‚æœä½¿ç”¨ç›¸åŒçš„User IDï¼ŒMemoBaseä¼šç´¯ç§¯ä¹‹å‰çš„æ•°æ®ï¼Œåé¢çš„å®éªŒä¼šå—åˆ°å‰é¢çš„å½±å“ã€‚

### Q: æ‰€æœ‰å®éªŒéƒ½å¤„ç†ç›¸åŒçš„æ•°æ®å—ï¼Ÿ
**A:** æ˜¯çš„ï¼æ‰€æœ‰å®éªŒéƒ½å¤„ç† `chats/mock_user/` é‡Œçš„5ä¸ªJSONæ–‡ä»¶ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯åˆ†å—å¤§å°Nã€‚

### Q: å¦‚ä½•çŸ¥é“å®éªŒæ˜¯å¦æ­£ç¡®è¿è¡Œï¼Ÿ
**A:** æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
- âœ… è¾“å‡ºæ˜¾ç¤º `Reading chat data from: chats/mock_user/`
- âœ… æ¯ä¸ªå®éªŒçš„MemoBase User IDä¸åŒ
- âœ… å¤„ç†äº†æ‰€æœ‰5ä¸ªJSONæ–‡ä»¶
- âœ… ä¸åŒNå€¼çš„åˆ†å—æ•°é‡ä¸åŒ

### Q: å®éªŒç»“æœå¦‚ä½•æ¯”è¾ƒï¼Ÿ
**A:** å› ä¸ºä½¿ç”¨ç›¸åŒçš„æµ‹è¯•æ•°æ®ï¼Œå¯ä»¥ç›´æ¥æ¯”è¾ƒï¼š
- N=5 vs N=10 vs N=20 çš„F1åˆ†æ•°
- æ‰¾åˆ°å‡†ç¡®æ€§å’Œé€Ÿåº¦çš„æœ€ä½³å¹³è¡¡ç‚¹

## ç³»ç»Ÿè¦æ±‚

### å¿…éœ€
- Python 3.10+
- Ollama å·²å®‰è£…
- æ¨¡å‹ qwen2.5:7b-instruct å·²ä¸‹è½½
- sudo æƒé™ï¼ˆç”¨äºåœæ­¢/å¯åŠ¨OllamaæœåŠ¡ï¼‰

### Pythonä¾èµ–
```bash
pip install memobase rich httpx
```

### æ£€æŸ¥ç¯å¢ƒ
```bash
# æ£€æŸ¥Ollama
which ollama
ollama list | grep qwen2.5

# æ£€æŸ¥æƒé™
sudo -v

# æ£€æŸ¥Pythonç‰ˆæœ¬
python3 --version
```

## æ•…éšœæ’æŸ¥

### Ollamaå¯åŠ¨å¤±è´¥
```bash
# æ‰‹åŠ¨å¯åŠ¨æµ‹è¯•
ollama serve

# æ£€æŸ¥ç«¯å£
curl http://127.0.0.1:11434/api/tags
```

### æƒé™é”™è¯¯
```bash
# éªŒè¯sudoæƒé™
sudo systemctl status ollama

# æˆäºˆè„šæœ¬æ‰§è¡Œæƒé™
chmod +x run_experiments.py extract.py evaluate.py
```

### æ¨¡å‹æœªæ‰¾åˆ°
```bash
# ä¸‹è½½æ¨¡å‹
ollama pull qwen2.5:7b-instruct

# éªŒè¯
ollama list
```

### ä¾èµ–ç¼ºå¤±
```bash
# å®‰è£…æ‰€æœ‰ä¾èµ–
pip install memobase rich httpx

# æˆ–ä½¿ç”¨requirements.txtï¼ˆå¦‚æœæœ‰ï¼‰
pip install -r requirements.txt
```

## é«˜çº§ç”¨æ³•

### ä¿®æ”¹Ollamaé…ç½®

ç¼–è¾‘ `run_experiments.py` ä¸­çš„ç¯å¢ƒå˜é‡ï¼š

```python
env = {
    "OLLAMA_FLASH_ATTENTION": "1",      # å¯ç”¨Flash Attention
    "OLLAMA_KV_CACHE_TYPE": "q8_0",     # KV Cacheé‡åŒ–ç±»å‹
    # å…¶ä»–å¯é€‰é…ç½®ï¼š
    # "OLLAMA_NUM_GPU": "1",
    # "OLLAMA_MAX_LOADED_MODELS": "1",
}
```

### æ›´æ¢æµ‹è¯•æ•°æ®

ä¿®æ”¹ `CHAT_DATA_DIR` å¸¸é‡ï¼š

```python
# run_experiments.py å’Œ extract.py
CHAT_DATA_DIR = "my_custom_data"  # æŒ‡å‘ chats/my_custom_data/
```

### é‡å¤å®éªŒéªŒè¯

```bash
# è¿è¡Œ3æ¬¡å®éªŒéªŒè¯ç¨³å®šæ€§
for i in {1..3}; do
    python3 run_experiments.py --rounds 5 10 20 --user-prefix run${i}
done
```

## å‘½ä»¤è¡Œå‚æ•°

### run_experiments.py

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|--------|------|
| `--rounds` | è¦æµ‹è¯•çš„Nå€¼åˆ—è¡¨ï¼ˆå¿…éœ€ï¼‰ | - | `--rounds 5 10 20` |
| `--user-prefix` | å®éªŒIDå‰ç¼€ | `exp` | `--user-prefix bench` |
| `--skip-eval` | è·³è¿‡è¯„ä¼°æ­¥éª¤ | False | `--skip-eval` |

### extract.py

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|--------|------|
| `--user-id` | MemoBase User ID | éšæœºç”Ÿæˆ | `--user-id test123` |
| `--rounds-per-chunk` | æ¯ä¸ªchunkçš„è½®æ•° | 5 | `-r 10` |
| `--project_url` | MemoBaseæœåŠ¡URL | `http://localhost:8019` | `-u http://localhost:8019` |
| `--project_token` | APIè®¿é—®ä»¤ç‰Œ | `secret` | `-t mytoken` |
| `--skip-profile` | è·³è¿‡è·å–ç”¨æˆ·ç”»åƒ | False | `--skip-profile` |

## å®Œæ•´ç¤ºä¾‹

### 1. åŸºç¡€å®éªŒ
```bash
python3 run_experiments.py --rounds 5 10 20
```

### 2. å¤§èŒƒå›´æµ‹è¯•
```bash
python3 run_experiments.py --rounds 3 5 7 10 15 20 30 40 50
```

### 3. é‡å¤éªŒè¯
```bash
python3 run_experiments.py --rounds 10 --user-prefix verify1
python3 run_experiments.py --rounds 10 --user-prefix verify2
python3 run_experiments.py --rounds 10 --user-prefix verify3
# å¯¹æ¯”ä¸‰æ¬¡ç»“æœçš„ç¨³å®šæ€§
```

### 4. æ€§èƒ½æµ‹è¯•ï¼ˆæ— è¯„ä¼°ï¼‰
```bash
python3 run_experiments.py --rounds 5 10 20 --skip-eval
```

## ç›¸å…³æ–‡ä»¶

- `run_experiments.py` - è‡ªåŠ¨åŒ–å®éªŒè¿è¡Œå™¨ä¸»è„šæœ¬
- `extract.py` - ä¿¡æ¯æå–è„šæœ¬
- `evaluate.py` - è¯„ä¼°è„šæœ¬
- `../../README.md` - å®Œæ•´æµ‹è¯•å¥—ä»¶æ–‡æ¡£
